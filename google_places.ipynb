{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read Data from API and insert it in the SQLite DB\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "import sqlite3\n",
    "\n",
    "final_data = []\n",
    "\n",
    "coordinates = ['48.8588897, 2.320041']\n",
    "keywords = ['restaurant', 'bar', 'hotel']\n",
    "radius = '2500'\n",
    "api_key = 'AIzaSyD3dMlrROmIJ4m8yDWyw2NpesbtAEv6eLg'  # ask ali if you really need it\n",
    "\n",
    "count = 0\n",
    "\n",
    "\n",
    "def generate_grid_coordinates(lat, lng, size, step):\n",
    "    latitudes = np.arange(lat - size / 2, lat + size / 2, step)\n",
    "    longitudes = np.arange(lng - size / 2, lng + size / 2, step)\n",
    "\n",
    "    return [(lat, lng) for lat in latitudes for lng in longitudes]\n",
    "\n",
    "\n",
    "# db conn\n",
    "connection = sqlite3.connect(\"googleplacesdb.db\")\n",
    "print(connection.total_changes)\n",
    "cursor = connection.cursor()\n",
    "\n",
    "center_lat = 48.8588897\n",
    "center_lng = 2.320041\n",
    "grid_size = 0.1  # in degrees\n",
    "step_size = 0.025  # in degrees\n",
    "coordinates = generate_grid_coordinates(\n",
    "    center_lat, center_lng, grid_size, step_size)\n",
    "\n",
    "for coordinate in coordinates:\n",
    "    lat, lng = coordinate\n",
    "    for keyword in keywords:\n",
    "        url = f'https://maps.googleapis.com/maps/api/place/nearbysearch/json?location={lat},{lng}&radius={radius}&keyword={keyword}&key={api_key}'\n",
    "        while True:\n",
    "            # Replaced the print(url) line\n",
    "            print(\n",
    "                f\"Requesting {keyword} at {lat}, {lng} ammount parsed: {count}\")\n",
    "            respon = requests.get(url)\n",
    "            jj = json.loads(respon.text)\n",
    "            results = jj['results']\n",
    "            for result in results:\n",
    "\n",
    "                name = result['name']\n",
    "                place_id = result['place_id']\n",
    "                lat = result['geometry']['location']['lat']\n",
    "                lng = result['geometry']['location']['lng']\n",
    "                rating = result['rating']\n",
    "                user_ratings_total = result['user_ratings_total']\n",
    "                types = result['types']\n",
    "                vicinity = result['vicinity']\n",
    "                business_status = result['business_status']\n",
    "\n",
    "                price_level = ''\n",
    "                if 'price_level' in result:\n",
    "                    price_level = result['price_level']\n",
    "\n",
    "                data = [name, keyword, business_status, place_id, lat, lng,\n",
    "                        rating, user_ratings_total, types, vicinity, price_level]\n",
    "                final_data.append(data)\n",
    "                count = count + 1\n",
    "\n",
    "                cursor.execute(\"INSERT INTO places VALUES (?,?,?,?,?,?,?,?,?,?,?)\",\n",
    "                               (data[0],\n",
    "                                data[1],\n",
    "                                data[2],\n",
    "                                data[3],\n",
    "                                data[4],\n",
    "                                data[5],\n",
    "                                data[6],\n",
    "                                data[7],\n",
    "                                ''.join(data[8]),\n",
    "                                data[9],\n",
    "                                data[10]))\n",
    "\n",
    "            time.sleep(1)\n",
    "\n",
    "            if 'next_page_token' not in jj:\n",
    "                break\n",
    "            else:\n",
    "                next_page_token = jj['next_page_token']\n",
    "                url = f'https://maps.googleapis.com/maps/api/place/nearbysearch/json?key={api_key}&pagetoken={next_page_token}'\n",
    "\n",
    "\n",
    "labels = ['name', 'api_keyword', 'business_status', 'place_id', 'lat',\n",
    "          'lng', 'rating', 'user_ratings_total', 'types', 'vicinity', 'price_level']\n",
    "export_dataframe_1_medium = pd.DataFrame.from_records(\n",
    "    final_data, columns=labels)\n",
    "export_dataframe_1_medium.to_csv('export_places.csv')\n",
    "\n",
    "\n",
    "print(f\"Total Entries Saved: {count}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "import numpy\n",
    "\n",
    "# Calculate correlation coefficient between rating and user_ratings_total\n",
    "rating_data = export_dataframe_1_medium['rating']\n",
    "user_ratings_data = export_dataframe_1_medium['user_ratings_total']\n",
    "correlation = np.corrcoef(rating_data, user_ratings_data)[0, 1]\n",
    "\n",
    "# Visualize data on a map\n",
    "map = folium.Map(location=[center_lat, center_lng], zoom_start=12)\n",
    "\n",
    "# Plot data points on the map\n",
    "for index, row in export_dataframe_1_medium.iterrows():\n",
    "    lat = row['lat']\n",
    "    lng = row['lng']\n",
    "    rating = row['rating']\n",
    "\n",
    "    marker_color = 'red' if rating >= 4.0 else 'blue'  # Adjust the rating condition as per your requirement\n",
    "    marker = folium.Marker([lat, lng], icon=folium.Icon(color=marker_color))\n",
    "    marker.add_to(map)\n",
    "\n",
    "# Add correlation to the map as a popup\n",
    "folium.Popup(f\"Correlation: {correlation:.2f}\").add_to(map)\n",
    "\n",
    "# Save and display the map\n",
    "map.save('data_points_map.html')\n",
    "map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "11 columns passed, passed data had 13 columns",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m~/opt/anaconda3/envs/travelgpt/lib/python3.10/site-packages/pandas/core/internals/construction.py:934\u001b[0m, in \u001b[0;36m_finalize_columns_and_data\u001b[0;34m(content, columns, dtype)\u001b[0m\n\u001b[1;32m    933\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 934\u001b[0m     columns \u001b[39m=\u001b[39m _validate_or_indexify_columns(contents, columns)\n\u001b[1;32m    935\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mAssertionError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m    936\u001b[0m     \u001b[39m# GH#26429 do not raise user-facing AssertionError\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/travelgpt/lib/python3.10/site-packages/pandas/core/internals/construction.py:981\u001b[0m, in \u001b[0;36m_validate_or_indexify_columns\u001b[0;34m(content, columns)\u001b[0m\n\u001b[1;32m    979\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m is_mi_list \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(columns) \u001b[39m!=\u001b[39m \u001b[39mlen\u001b[39m(content):  \u001b[39m# pragma: no cover\u001b[39;00m\n\u001b[1;32m    980\u001b[0m     \u001b[39m# caller's responsibility to check for this...\u001b[39;00m\n\u001b[0;32m--> 981\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAssertionError\u001b[39;00m(\n\u001b[1;32m    982\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(columns)\u001b[39m}\u001b[39;00m\u001b[39m columns passed, passed data had \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    983\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(content)\u001b[39m}\u001b[39;00m\u001b[39m columns\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    984\u001b[0m     )\n\u001b[1;32m    985\u001b[0m \u001b[39mif\u001b[39;00m is_mi_list:\n\u001b[1;32m    986\u001b[0m     \u001b[39m# check if nested list column, length of each sub-list should be equal\u001b[39;00m\n",
      "\u001b[0;31mAssertionError\u001b[0m: 11 columns passed, passed data had 13 columns",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 22\u001b[0m\n\u001b[1;32m     19\u001b[0m data \u001b[39m=\u001b[39m cur\u001b[39m.\u001b[39mfetchall()\n\u001b[1;32m     21\u001b[0m \u001b[39m# Load the data into a pandas DataFrame\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mDataFrame(data, columns\u001b[39m=\u001b[39;49m[\u001b[39m'\u001b[39;49m\u001b[39mname\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mapi_keyword\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mbusiness_status\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mplace_id\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mlat\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mlng\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mrating\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39muser_ratings_total\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mtypes\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mvicinity\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mprice_level\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[1;32m     24\u001b[0m \u001b[39m# Convert 'lat', 'lng', 'rating' and 'price_level' to numeric\u001b[39;00m\n\u001b[1;32m     25\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39mlat\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mto_numeric(df[\u001b[39m'\u001b[39m\u001b[39mlat\u001b[39m\u001b[39m'\u001b[39m], errors\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mcoerce\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/travelgpt/lib/python3.10/site-packages/pandas/core/frame.py:781\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    779\u001b[0m     \u001b[39mif\u001b[39;00m columns \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    780\u001b[0m         columns \u001b[39m=\u001b[39m ensure_index(columns)\n\u001b[0;32m--> 781\u001b[0m     arrays, columns, index \u001b[39m=\u001b[39m nested_data_to_arrays(\n\u001b[1;32m    782\u001b[0m         \u001b[39m# error: Argument 3 to \"nested_data_to_arrays\" has incompatible\u001b[39;49;00m\n\u001b[1;32m    783\u001b[0m         \u001b[39m# type \"Optional[Collection[Any]]\"; expected \"Optional[Index]\"\u001b[39;49;00m\n\u001b[1;32m    784\u001b[0m         data,\n\u001b[1;32m    785\u001b[0m         columns,\n\u001b[1;32m    786\u001b[0m         index,  \u001b[39m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m    787\u001b[0m         dtype,\n\u001b[1;32m    788\u001b[0m     )\n\u001b[1;32m    789\u001b[0m     mgr \u001b[39m=\u001b[39m arrays_to_mgr(\n\u001b[1;32m    790\u001b[0m         arrays,\n\u001b[1;32m    791\u001b[0m         columns,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    794\u001b[0m         typ\u001b[39m=\u001b[39mmanager,\n\u001b[1;32m    795\u001b[0m     )\n\u001b[1;32m    796\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/travelgpt/lib/python3.10/site-packages/pandas/core/internals/construction.py:498\u001b[0m, in \u001b[0;36mnested_data_to_arrays\u001b[0;34m(data, columns, index, dtype)\u001b[0m\n\u001b[1;32m    495\u001b[0m \u001b[39mif\u001b[39;00m is_named_tuple(data[\u001b[39m0\u001b[39m]) \u001b[39mand\u001b[39;00m columns \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    496\u001b[0m     columns \u001b[39m=\u001b[39m ensure_index(data[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39m_fields)\n\u001b[0;32m--> 498\u001b[0m arrays, columns \u001b[39m=\u001b[39m to_arrays(data, columns, dtype\u001b[39m=\u001b[39;49mdtype)\n\u001b[1;32m    499\u001b[0m columns \u001b[39m=\u001b[39m ensure_index(columns)\n\u001b[1;32m    501\u001b[0m \u001b[39mif\u001b[39;00m index \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/travelgpt/lib/python3.10/site-packages/pandas/core/internals/construction.py:840\u001b[0m, in \u001b[0;36mto_arrays\u001b[0;34m(data, columns, dtype)\u001b[0m\n\u001b[1;32m    837\u001b[0m     data \u001b[39m=\u001b[39m [\u001b[39mtuple\u001b[39m(x) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m data]\n\u001b[1;32m    838\u001b[0m     arr \u001b[39m=\u001b[39m _list_to_arrays(data)\n\u001b[0;32m--> 840\u001b[0m content, columns \u001b[39m=\u001b[39m _finalize_columns_and_data(arr, columns, dtype)\n\u001b[1;32m    841\u001b[0m \u001b[39mreturn\u001b[39;00m content, columns\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/travelgpt/lib/python3.10/site-packages/pandas/core/internals/construction.py:937\u001b[0m, in \u001b[0;36m_finalize_columns_and_data\u001b[0;34m(content, columns, dtype)\u001b[0m\n\u001b[1;32m    934\u001b[0m     columns \u001b[39m=\u001b[39m _validate_or_indexify_columns(contents, columns)\n\u001b[1;32m    935\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mAssertionError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m    936\u001b[0m     \u001b[39m# GH#26429 do not raise user-facing AssertionError\u001b[39;00m\n\u001b[0;32m--> 937\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(err) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m    939\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(contents) \u001b[39mand\u001b[39;00m contents[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m np\u001b[39m.\u001b[39mobject_:\n\u001b[1;32m    940\u001b[0m     contents \u001b[39m=\u001b[39m convert_object_array(contents, dtype\u001b[39m=\u001b[39mdtype)\n",
      "\u001b[0;31mValueError\u001b[0m: 11 columns passed, passed data had 13 columns"
     ]
    }
   ],
   "source": [
    "#heatmap\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import folium\n",
    "import seaborn as sns\n",
    "from folium.plugins import HeatMap\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Connect to the SQLite database\n",
    "conn = sqlite3.connect('googleplacesdb.db')\n",
    "\n",
    "# Create a cursor object\n",
    "cur = conn.cursor()\n",
    "\n",
    "# Execute a SQL query to select all fields from your table\n",
    "cur.execute(\"SELECT * FROM places\")\n",
    "\n",
    "# Fetch all results from the executed SQL query\n",
    "data = cur.fetchall()\n",
    "\n",
    "# Load the data into a pandas DataFrame\n",
    "df = pd.DataFrame(data, columns=['name', 'api_keyword', 'business_status', 'place_id', 'lat', 'lng', 'rating', 'user_ratings_total', 'types', 'vicinity', 'price_level'])\n",
    "\n",
    "# Convert 'lat', 'lng', 'rating' and 'price_level' to numeric\n",
    "df['lat'] = pd.to_numeric(df['lat'], errors='coerce')\n",
    "df['lng'] = pd.to_numeric(df['lng'], errors='coerce')\n",
    "df['rating'] = pd.to_numeric(df['rating'], errors='coerce')\n",
    "df['price_level'] = pd.to_numeric(df['price_level'], errors='coerce')\n",
    "\n",
    "# Create a map centered around the average coordinates\n",
    "m = folium.Map(location=[df['lat'].mean(), df['lng'].mean()], zoom_start=10, control_scale=True)\n",
    "\n",
    "# Drop any rows with missing 'lat' or 'lng' data\n",
    "df = df.dropna(subset=['lat', 'lng'])\n",
    "\n",
    "# Create a list of coordinates\n",
    "heat_data = [[row['lat'], row['lng']] for index, row in df.iterrows()]\n",
    "\n",
    "# Add the heatmap to the map\n",
    "HeatMap(heat_data).add_to(m)\n",
    "\n",
    "# Save the map to an HTML file\n",
    "m.save('heatmap.html')\n",
    "\n",
    "# Handle NaN values in 'price_level' and 'rating' column\n",
    "df['price_level'] = df['price_level'].fillna(0)\n",
    "df['rating'] = df['rating'].fillna(0)\n",
    "\n",
    "# Check for correlation between 'rating' and 'price_level'\n",
    "correlation = df['rating'].corr(df['price_level'])\n",
    "print(f'Correlation between user rating and price: {correlation}')\n",
    "\n",
    "# Create a scatter plot of 'rating' and 'price_level'\n",
    "sns.scatterplot(x='price_level', y='rating', data=df)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "con = sqlite3.connect(\"googleplacesdb.db\")\n",
    "\n",
    "# Create a cursor object\n",
    "cur = con.cursor()\n",
    "# Execute the SQL query\n",
    "cur.execute('''CREATE TABLE IF NOT EXISTS temp_places AS\n",
    "SELECT DISTINCT *\n",
    "FROM places;''')\n",
    "\n",
    "cur.execute('''DROP TABLE places;''')\n",
    "\n",
    "cur.execute('''ALTER TABLE temp_places RENAME TO places;''')\n",
    "con.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "travelgpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
